{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from inputs import texts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f7458ce50626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_gram_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_candidates(ngram_range,stop_words,doc):\n",
    "    count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n",
    "    candidates = count.get_feature_names()\n",
    "    return candidates\n",
    "\n",
    "def get_embeddings(model,doc,candidates):\n",
    "    doc_embedding = model.encode([doc])\n",
    "    candidate_embedding = model.encode(candidates)\n",
    "    \n",
    "    return doc_embedding,candidate_embedding\n",
    "\n",
    "def get_keywords(doc_embedding,candidate_embedding,topk=5):\n",
    "    \n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    keywords = [candidates[index] for index in distances.argsort()[0][-topk:]]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def main(doc,ngram_range,stop_words,model,topk=5):\n",
    "    \n",
    "    candidates = generate_candidates(ngram_range,stop_words,doc)\n",
    "    \n",
    "    doc_embed,candidate_embed = get_embeddings(model,doc,candidates)\n",
    "    \n",
    "    keywords = get_keywords(doc_embed,candidate_embed,topk)\n",
    "    \n",
    "    return keywords\n",
    "    \n",
    "    \n",
    "main(doc,n_gram_range,stop_words,model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candiadtate keyword\n",
    "n_gram_range = (1, 1)\n",
    "\n",
    "stop_words = \"english\"\n",
    "\n",
    "doc= texts[-1]\n",
    "# Extract candidate words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n",
    "candidates = count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19',\n",
       " '380',\n",
       " '40',\n",
       " '73',\n",
       " '78',\n",
       " 'according',\n",
       " 'american',\n",
       " 'appear',\n",
       " 'arab',\n",
       " 'association',\n",
       " 'backing',\n",
       " 'bahrain',\n",
       " 'beijing',\n",
       " 'biological',\n",
       " 'carried',\n",
       " 'china',\n",
       " 'claimed',\n",
       " 'company',\n",
       " 'concluded',\n",
       " 'countries',\n",
       " 'covid',\n",
       " 'data',\n",
       " 'details',\n",
       " 'developed',\n",
       " 'east',\n",
       " 'effective',\n",
       " 'egypt',\n",
       " 'emergency',\n",
       " 'emirates',\n",
       " 'health',\n",
       " 'institute',\n",
       " 'involved',\n",
       " 'jordan',\n",
       " 'journal',\n",
       " 'just',\n",
       " 'local',\n",
       " 'medical',\n",
       " 'middle',\n",
       " 'online',\n",
       " 'organization',\n",
       " 'participants',\n",
       " 'partners',\n",
       " 'placebo',\n",
       " 'previously',\n",
       " 'products',\n",
       " 'provided',\n",
       " 'published',\n",
       " 'recently',\n",
       " 'report',\n",
       " 'researchers',\n",
       " 'safe',\n",
       " 'say',\n",
       " 'scientists',\n",
       " 'sinopharm',\n",
       " 'study',\n",
       " 'trial',\n",
       " 'uae',\n",
       " 'united',\n",
       " 'use',\n",
       " 'used',\n",
       " 'vaccines',\n",
       " 'waiting',\n",
       " 'won',\n",
       " 'world',\n",
       " 'wuhan']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeddings\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([doc])\n",
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity\n",
    "top_n = 5\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = distances.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in distances.argsort()[0][-top_n:][::-1]:\n",
    "    print(candidates[index],distances[0][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diversification\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def max_sum_sim(doc_embedding, word_embeddings, words, top_n, nr_candidates):\n",
    "    # Calculate distances and extract keywords\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, \n",
    "                                            candidate_embeddings)\n",
    "\n",
    "    # Get top_n words as candidates based on cosine similarity\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # Calculate the combination of words that are the least similar to each other\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    return [words_vals[idx] for idx in candidate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmr(doc_embedding, word_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # Extract similarity within words, and between words and the document\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
    "    word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    # Initialize candidates and already choose best keyword/keyphras\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        # Extract similarities within candidates and\n",
    "        # between candidates and selected keywords/phrases\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # Calculate MMR\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # Update keywords & candidates\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'htbuilder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-73ee73a0e575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhtbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHtmlElement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhtbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'htbuilder'"
     ]
    }
   ],
   "source": [
    "import streamlit.components.v1\n",
    "\n",
    "from htbuilder import H, HtmlElement, styles\n",
    "from htbuilder.units import unit\n",
    "\n",
    "# Only works in 3.7+: from htbuilder import div, span\n",
    "div = H.div\n",
    "span = H.span\n",
    "\n",
    "# Only works in 3.7+: from htbuilder.units import px, rem, em\n",
    "px = unit.px\n",
    "rem = unit.rem\n",
    "em = unit.em\n",
    "\n",
    "\n",
    "def annotation(body, label=\"\", background=\"#ddd\", color=\"#333\", **style):\n",
    "    \"\"\"Build an HtmlElement span object with the given body and annotation label.\n",
    "    The end result will look something like this:\n",
    "        [body | label]\n",
    "    Parameters\n",
    "    ----------\n",
    "    body : string\n",
    "        The string to put in the \"body\" part of the annotation.\n",
    "    label : string\n",
    "        The string to put in the \"label\" part of the annotation.\n",
    "    background : string\n",
    "        The color to use for the background \"chip\" containing this annotation.\n",
    "    color : string\n",
    "        The color to use for the body and label text.\n",
    "    **style : dict\n",
    "        Any CSS you want to use to customize the containing \"chip\".\n",
    "    Examples\n",
    "    --------\n",
    "    Produce a simple annotation with default colors:\n",
    "    >>> annotation(\"apple\", \"fruit\")\n",
    "    Produce an annotation with custom colors:\n",
    "    >>> annotation(\"apple\", \"fruit\", background=\"#FF0\", color=\"black\")\n",
    "    Produce an annotation with crazy CSS:\n",
    "    >>> annotation(\"apple\", \"fruit\", background=\"#FF0\", border=\"1px dashed red\")\n",
    "    \"\"\"\n",
    "\n",
    "    if \"font_family\" not in style:\n",
    "        style[\"font_family\"] = \"sans-serif\"\n",
    "\n",
    "    return span(\n",
    "        style=styles(\n",
    "            background=background,\n",
    "            border_radius=rem(0.33),\n",
    "            color=color,\n",
    "            padding=(rem(0.17), rem(0.67)),\n",
    "            display=\"inline-flex\",\n",
    "            justify_content=\"center\",\n",
    "            align_items=\"center\",\n",
    "            **style,\n",
    "        )\n",
    "    )(\n",
    "        body,\n",
    "        span(\n",
    "            style=styles(\n",
    "                color=color,\n",
    "                font_size=em(0.67),\n",
    "                opacity=0.5,\n",
    "                padding_left=rem(0.5),\n",
    "                text_transform=\"uppercase\",\n",
    "                margin_bottom=px(-2),\n",
    "            )\n",
    "        )(label)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
